{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czrl3DYr_5X-"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVaLGyya9j1Y"
      },
      "source": [
        "### 1. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXeBhEod-DX7",
        "outputId": "9401da6f-98cc-4cfe-b590-7fca58e5a547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/ML-Sec\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/ML-Sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsMPxoSK9fTj"
      },
      "outputs": [],
      "source": [
        "# # Only required to run once to extract files\n",
        "# !tar -xvf lingspam_public.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxeabIi98hAS",
        "outputId": "390e34aa-68c5-48d8-ff52-e7ff15daeef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded lingspam_public/lemm_stop/part1 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part10 into testing data\n",
            "Successfully loaded lingspam_public/lemm_stop/part2 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part3 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part4 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part5 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part6 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part7 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part8 into training data\n",
            "Successfully loaded lingspam_public/lemm_stop/part9 into training data\n"
          ]
        }
      ],
      "source": [
        "data_path = 'lingspam_public/lemm_stop/'\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "for subdirectory in sorted(os.listdir(data_path)):\n",
        "  subdirectory_path = os.path.join(data_path, subdirectory)\n",
        "  if os.path.isdir(subdirectory_path):\n",
        "    if \"part10\" not in str(subdirectory_path).split('/'):\n",
        "      for filename in os.listdir(subdirectory_path):\n",
        "        with open(os.path.join(subdirectory_path, filename), \"r\") as file:\n",
        "          content = file.read()\n",
        "          label = 1 if \"spmsg\" in filename else 0\n",
        "          y_train.append(label)\n",
        "          x_train.append(content)\n",
        "      print(f\"Successfully loaded {subdirectory_path} into training data\")\n",
        "    else:\n",
        "      for filename in os.listdir(subdirectory_path):\n",
        "        with open(os.path.join(subdirectory_path, filename), \"r\") as file:\n",
        "          content = file.read()\n",
        "          label = 1 if \"spmsg\" in filename else 0\n",
        "          y_test.append(label)\n",
        "          x_test.append(content)\n",
        "      print(f\"Successfully loaded {subdirectory_path} into testing data\")\n",
        "  else:\n",
        "    print(f\"Error: {subdirectory_path} does not exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idqYzEZoNSK7"
      },
      "outputs": [],
      "source": [
        "# # Printing a positive (spam) sample:\n",
        "# for i in range(100):\n",
        "#   if y_train[i] == 1:\n",
        "#     print(f\"Sample: \\n{x_train[i]}\")\n",
        "#     print(f\"Label: {y_train[i]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGeCBz8-f9j-",
        "outputId": "25e0fc00-6430-49e7-fa22-27da89fe299d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train: 2602, x_test: 291\n",
            "y_train: 2602, y_test: 291\n",
            "\n",
            "X: 2893, y: 2893\n"
          ]
        }
      ],
      "source": [
        "# Creating a dataset\n",
        "\n",
        "X = x_train + x_test\n",
        "y = y_train + y_test\n",
        "\n",
        "print(f\"x_train: {len(x_train)}, x_test: {len(x_test)}\\ny_train: {len(y_train)}, y_test: {len(y_test)}\\n\\nX: {len(X)}, y: {len(y)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyV8yC5QBZav"
      },
      "source": [
        "### 2. Feature Selection using Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sukM_yi5VKlZ"
      },
      "outputs": [],
      "source": [
        "# Binary Features\n",
        "count_vectorizer = CountVectorizer(binary=True)\n",
        "X_binary = count_vectorizer.fit_transform(X)\n",
        "\n",
        "# Term Frequency Features\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tf = tfidf_vectorizer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNcLWEieWeEi"
      },
      "outputs": [],
      "source": [
        "# Information Gain (Mutual Information)\n",
        "mi = mutual_info_classif(X_binary, y)\n",
        "feature_indices = np.argsort(mi)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV4Xz8xGvX64"
      },
      "outputs": [],
      "source": [
        "N = [10, 100, 1000]\n",
        "\n",
        "X_selected = {'binary': {}, 'tf': {}}\n",
        "\n",
        "for n in N:\n",
        "  top_N_features = feature_indices[:n]\n",
        "  X_selected['binary'][n] = X_binary[:, top_N_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKHOevEjryUT"
      },
      "outputs": [],
      "source": [
        "mi_tf = mutual_info_classif(X_tf, y)\n",
        "tf_feature_indices = np.argsort(mi_tf)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ThDoD6Yvak6"
      },
      "outputs": [],
      "source": [
        "for n in N:\n",
        "  top_N_features = feature_indices[:n]\n",
        "  X_selected['tf'][n] = X_tf[:, top_N_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9KGVkL70BbY",
        "outputId": "f2aaaabe-d5f2-4f75-ea47-a34c9c5bf4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 words from Part(1):\n",
            "1 language\n",
            "2 remove\n",
            "3 linguistic\n",
            "4 university\n",
            "5 free\n",
            "6 money\n",
            "7 click\n",
            "8 our\n",
            "9 today\n",
            "10 sell\n"
          ]
        }
      ],
      "source": [
        "feature_names = count_vectorizer.get_feature_names_out()\n",
        "sorted_features = [feature_names[i] for i in np.argsort(mi)[::-1]]\n",
        "\n",
        "top_N = 10\n",
        "# Print the top N words\n",
        "print(f\"Top {top_N} words from Part(1):\")\n",
        "for i, word in enumerate(sorted_features[:top_N]):\n",
        "    print(i+1, word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO77AibfBdhk"
      },
      "source": [
        "### 3. Naive Bayes\n",
        "##### 3.1 Bernoulli NB classifier with binary features;\n",
        "##### 3.2. Multinomial NB with binary features; and\n",
        "##### 3.3. Multinomial NB with term frequency (TF) features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iobVilqDDZIj",
        "outputId": "76263108-7799-4b7d-a723-af074b27dac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bernoulli NB - Top-10 Features:\n",
            "Spam Precision: 0.928571\n",
            "Spam Recall: 0.795918\n",
            "Training Latency: 0.005000s\n",
            "Inference Latency: 0.000742s\n",
            "\n",
            "Multinomial NB (Binary) - Top-10 Features:\n",
            "Spam Precision: 0.928571\n",
            "Spam Recall: 0.795918\n",
            "Training Latency: 0.005762s\n",
            "Inference Latency: 0.000393s\n",
            "\n",
            "Multinomial NB (TF) - Top-10 Features:\n",
            "Spam Precision: 0.000000\n",
            "Spam Recall: 0.000000\n",
            "Training Latency: 0.003252s\n",
            "Inference Latency: 0.000522s\n",
            "\n",
            "Bernoulli NB - Top-100 Features:\n",
            "Spam Precision: 1.000000\n",
            "Spam Recall: 0.714286\n",
            "Training Latency: 0.004330s\n",
            "Inference Latency: 0.000912s\n",
            "\n",
            "Multinomial NB (Binary) - Top-100 Features:\n",
            "Spam Precision: 0.978723\n",
            "Spam Recall: 0.938776\n",
            "Training Latency: 0.002305s\n",
            "Inference Latency: 0.000320s\n",
            "\n",
            "Multinomial NB (TF) - Top-100 Features:\n",
            "Spam Precision: 1.000000\n",
            "Spam Recall: 0.367347\n",
            "Training Latency: 0.003072s\n",
            "Inference Latency: 0.000365s\n",
            "\n",
            "Bernoulli NB - Top-1000 Features:\n",
            "Spam Precision: 1.000000\n",
            "Spam Recall: 0.755102\n",
            "Training Latency: 0.004656s\n",
            "Inference Latency: 0.000865s\n",
            "\n",
            "Multinomial NB (Binary) - Top-1000 Features:\n",
            "Spam Precision: 1.000000\n",
            "Spam Recall: 0.938776\n",
            "Training Latency: 0.006369s\n",
            "Inference Latency: 0.000725s\n",
            "\n",
            "Multinomial NB (TF) - Top-1000 Features:\n",
            "Spam Precision: 1.000000\n",
            "Spam Recall: 0.775510\n",
            "Training Latency: 0.005103s\n",
            "Inference Latency: 0.000541s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifiers = [\n",
        "  (\"Bernoulli NB\", BernoulliNB()),\n",
        "  (\"Multinomial NB (Binary)\", MultinomialNB()),\n",
        "  (\"Multinomial NB (TF)\", MultinomialNB())\n",
        "]\n",
        "\n",
        "for n in N:\n",
        "  for name, classifier in classifiers:\n",
        "    vectorizer = 'tf' if '(TF)' in name.split() else 'binary'\n",
        "\n",
        "    train_start = time.time()\n",
        "    classifier.fit(X_selected[vectorizer][n][:2602], y_train)\n",
        "    train_latency = time.time() - train_start\n",
        "    test_start = time.time()\n",
        "    # Predict on the test data\n",
        "    y_pred = classifier.predict(X_selected[vectorizer][n][2602:])\n",
        "    test_latency = time.time() - test_start\n",
        "\n",
        "    # Calculate spam precision and recall\n",
        "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
        "    recall = recall_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "    print(f\"{name} - Top-{n} Features:\")\n",
        "    print(f\"Spam Precision: {precision:.6f}\")\n",
        "    print(f\"Spam Recall: {recall:.6f}\")\n",
        "    print(f\"Training Latency: {train_latency:.6f}s\")\n",
        "    print(f\"Inference Latency: {test_latency:.6f}s\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvXyXbXEDZvT"
      },
      "source": [
        "### 4. Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE13-ySLBK2P",
        "outputId": "0f66c25f-964e-4aac-e886-7d4e855bacf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best SVM Model with Cross-Validation for binary vectorizer:\n",
            "Best Hyperparameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Spam Precision (SVM): 1.0\n",
            "Spam Recall (SVM): 0.02040816326530612\n",
            "\n",
            "Best SVM Model with Cross-Validation for tf vectorizer:\n",
            "Best Hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Spam Precision (SVM): 0.9583333333333334\n",
            "Spam Recall (SVM): 0.9387755102040817\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n = 100 # Number of features used\n",
        "vectorizers = ['binary', 'tf'] #using and testing both vectorization methods\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "svm_model = SVC()\n",
        "\n",
        "for vectorizer in vectorizers:\n",
        "  grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='recall')\n",
        "  grid_search.fit(X_selected[vectorizer][n][:2602], y_train)\n",
        "\n",
        "  best_params = grid_search.best_params_\n",
        "\n",
        "  best_svm_model = SVC(**best_params)\n",
        "  best_svm_model.fit(X_selected[vectorizer][n][:2602], y_train)\n",
        "\n",
        "  y_pred_svm = best_svm_model.predict(X_selected['tf'][n][2602:])\n",
        "\n",
        "  precision_svm = precision_score(y_test, y_pred_svm, pos_label=1)\n",
        "  recall_svm = recall_score(y_test, y_pred_svm, pos_label=1)\n",
        "\n",
        "  print(f\"Best SVM Model with Cross-Validation for {vectorizer} vectorizer:\")\n",
        "  print(\"Best Hyperparameters:\", best_params)\n",
        "  print(f\"Spam Precision (SVM): {precision_svm}\")\n",
        "  print(f\"Spam Recall (SVM): {recall_svm}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq5Hfs7GDvbM",
        "outputId": "6c2d47e5-5144-4b8c-f219-68a7a3f14b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best SVM Model with Cross-Validation for binary vectorizer:\n",
            "Best Hyperparameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Spam Precision (SVM): 1.0\n",
            "Spam Recall (SVM): 0.6326530612244898\n",
            "\n",
            "Best SVM Model with Cross-Validation for tf vectorizer:\n",
            "Best Hyperparameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Spam Precision (SVM): 0.9019607843137255\n",
            "Spam Recall (SVM): 0.9387755102040817\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n = 100 # Number of features used\n",
        "vectorizers = ['binary', 'tf'] #using and testing both vectorization methods\n",
        "\n",
        "# Calculated class weights since the dataset has large class imbalance and SVM does not perform well on large class imbalances\n",
        "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "svm_model = SVC(class_weight={0: class_weights[0], 1: class_weights[1]})\n",
        "\n",
        "for vectorizer in vectorizers:\n",
        "  grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='recall')\n",
        "  grid_search.fit(X_selected[vectorizer][n][:2602], y_train)\n",
        "\n",
        "  best_params = grid_search.best_params_\n",
        "\n",
        "  best_svm_model = SVC(**best_params, class_weight={0: class_weights[0], 1: class_weights[1]})\n",
        "  best_svm_model.fit(X_selected[vectorizer][n][:2602], y_train)\n",
        "\n",
        "  y_pred_svm = best_svm_model.predict(X_selected['tf'][n][2602:])\n",
        "\n",
        "  precision_svm = precision_score(y_test, y_pred_svm, pos_label=1)\n",
        "  recall_svm = recall_score(y_test, y_pred_svm, pos_label=1)\n",
        "\n",
        "  print(f\"Best SVM Model with Cross-Validation for {vectorizer} vectorizer:\")\n",
        "  print(\"Best Hyperparameters:\", best_params)\n",
        "  print(f\"Spam Precision (SVM): {precision_svm}\")\n",
        "  print(f\"Spam Recall (SVM): {recall_svm}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rhD61XuC-VPX"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}